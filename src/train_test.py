# -*- coding: utf-8 -*-
"""train_test

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kn3XAwDbNXl44IY1GL-r84K61CCwhJOz
"""

import pandas as pd
import os
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import lightgbm as lgb

# Función para limpiar los nombres de las columnas
def clean_column_names(df):
    df.columns = [col.replace(',', '_').replace(' ', '_') for col in df.columns]
    return df

# Función para cargar y preparar la tabla transformada
def read_file_csv(train_filename, test_filename):
    train_full = pd.read_csv(os.path.join('../data/processed', train_filename)).set_index('ID')
    test_full = pd.read_csv(os.path.join('../data/processed', test_filename)).set_index('ID')

    categorical_cols = ['StateHoliday', 'StoreType', 'Assortment', 'PromoInterval']

    # Codificar las variables categóricas
    train_full_encoded = pd.get_dummies(train_full, columns=categorical_cols, drop_first=True)
    test_full_encoded = pd.get_dummies(test_full, columns=categorical_cols, drop_first=True)

    # Alineamos ambos DataFrames para que tengan las mismas columnas
    train_full_encoded, test_full_encoded = train_full_encoded.align(test_full_encoded, join='outer', axis=1, fill_value=0)

    # Limpiamos los nombres de las columnas
    train_full_encoded = clean_column_names(train_full_encoded)
    test_full_encoded = clean_column_names(test_full_encoded)

    return train_full_encoded, test_full_encoded

# Función para dividir el conjunto de datos en entrenamiento y validación
def split_data(train_full_encoded):
    # Excluir columnas que no se usan para el modelado
    exclude_cols = ['Sales', 'Customers', 'Date', 'CompetitionOpenDate', 'Promo2StartDate']
    features_columns = [col for col in train_full_encoded.columns if col not in exclude_cols]
    target = 'Sales'

    X_model = train_full_encoded[features_columns]
    y_model = train_full_encoded[target]

    # Dividimos los datos en conjunto de entrenamiento y validación (80%/20%)
    X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.2, random_state=42)

    return X_train, X_val, y_train, y_val

# Función para calcular el RMSPE
def rmspe(y_true, y_pred):
    return np.sqrt(np.mean(((y_true - y_pred) / y_true) ** 2))

# Función para guardar los resultados en un archivo CSV
def save_results_to_csv(resultados_df, output_dir='../data/resultados'):
    # Asegurarse de que el directorio exista
    os.makedirs(output_dir, exist_ok=True)

    # Guardar los resultados en un archivo CSV
    results_file = os.path.join(output_dir, 'resultados_comparacion.csv')
    resultados_df.to_csv(results_file, index=False)
    print(f"Los resultados se han guardado en: {results_file}")

# Entrenamiento y evaluación de modelos
def train_and_evaluate_models(X_train, X_val, y_train, y_val):
    # Modelos a evaluar
    models = {
        "Regresión Lineal": LinearRegression(),
        "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
        "Gradient Boosting": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),
        "XGBoost": xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbosity=0),
        "LightGBM": lgb.LGBMRegressor(n_estimators=100, learning_rate=0.05, random_state=42)
    }

    resultados = {}

    # Entrenamos y evaluamos cada modelo
    for model_name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_val)
        rmspe_value = rmspe(y_val, y_pred)
        resultados[model_name] = rmspe_value
        print(f"RMSPE - {model_name}: {rmspe_value:.4f}")

    # Ordenar los resultados por RMSPE (de menor a mayor)
    resultados_df = pd.DataFrame(list(resultados.items()), columns=["Modelo", "RMSPE"])
    resultados_df.sort_values(by="RMSPE", inplace=True)

    print("Comparación de Modelos (RMSPE):")
    print(resultados_df)

    # Guardar los resultados en un archivo CSV
    save_results_to_csv(resultados_df)

# Función principal
def main():
    # Cargar y preparar los datos
    train_full_encoded, test_full_encoded = read_file_csv('train_processed.csv', 'test_processed.csv')
    print('Datos cargados y procesados correctamente.')

    # Dividir los datos en entrenamiento y validación
    X_train, X_val, y_train, y_val = split_data(train_full_encoded)
    print(f"Tamaño de X_train: {X_train.shape}, X_val: {X_val.shape}")

    # Entrenar y evaluar los modelos
    train_and_evaluate_models(X_train, X_val, y_train, y_val)

if __name__ == "__main__":
    main()